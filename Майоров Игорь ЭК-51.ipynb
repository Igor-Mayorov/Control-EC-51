{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем наш дата сет. Мы имеем дата сет из 10 колонок (Age, Sex, ALP, ALT, AST, BIL, CHE, CHOL, CREA, Category).Среди данных есть как и числовые так и качественные переменныею. Крайний столбец Category выступает как классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С помощью этой чанки мы загрузим  необходимые библиотеки для начала работы (Numpy, Matplotlib.pyplot ,Pandas)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим над исходный датасет. \n",
    "df = pd.read_csv('mayorov.csv', sep=',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>38.5</td>\n",
       "      <td>52.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>38.5</td>\n",
       "      <td>70.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>46.9</td>\n",
       "      <td>74.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>43.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>39.2</td>\n",
       "      <td>74.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62</td>\n",
       "      <td>f</td>\n",
       "      <td>32.0</td>\n",
       "      <td>416.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>24.0</td>\n",
       "      <td>102.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>29.0</td>\n",
       "      <td>87.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59</td>\n",
       "      <td>f</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex   ALB    ALP    ALT    AST   BIL  CHOL   CREA  Category\n",
       "0     32   m  38.5   52.5    7.7   22.1   7.5  3.23  106.0         0\n",
       "1     32   m  38.5   70.3   18.0   24.7   3.9  4.80   74.0         0\n",
       "2     32   m  46.9   74.7   36.2   52.6   6.1  5.20   86.0         0\n",
       "3     32   m  43.2   52.0   30.6   22.6  18.9  4.74   80.0         0\n",
       "4     32   m  39.2   74.1   32.6   24.8   9.6  4.32   76.0         0\n",
       "..   ...  ..   ...    ...    ...    ...   ...   ...    ...       ...\n",
       "610   62   f  32.0  416.6    5.9  110.3  50.0  6.30   55.7         1\n",
       "611   64   f  24.0  102.8    2.9   44.4  20.0  3.02   63.0         1\n",
       "612   64   f  29.0   87.3    3.5   99.0  48.0  3.63   66.7         1\n",
       "613   46   f  33.0    NaN   39.0   62.0  20.0  4.20   52.0         1\n",
       "614   59   f  36.0    NaN  100.0   80.0  12.0  5.30   67.0         1\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Здесь можно проверить что было загруженно в переменную df.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для последующей корректной работы проверим наш датасет на пропуски.\n",
    "def fill_missing_num(x):\n",
    "    num_var = list(x._get_numeric_data().columns)\n",
    "    for col_names in num_var:        \n",
    "        prep_med = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        prep_med.fit(x[num_var])\n",
    "        x[num_var] = prep_med.transform(x[num_var])\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним присутствующие пропуски с помощью SimpleImputer.\n",
    "from sklearn.impute import SimpleImputer\n",
    "df = fill_missing_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С пмощью этой чанки мы произведем кодиррование наших качественных перменных, в нашем случае только столбец Sex.\n",
    "def encoding_char(x):\n",
    "    char_var = list(set(x.columns) - set(x._get_numeric_data().columns))\n",
    "    for col_names in char_var:\n",
    "        f = pd.factorize(x[col_names])\n",
    "        x[col_names] = pd.factorize(x[col_names])[0]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encoding_char(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наш датасет следует разделить на тестовый и учебный в определенной пропорции. Пусть это будет  20/80.\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Производим шкалирование наших данных без нашей эдогенной переменной Category.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.305797\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.232     \n",
      "Dependent Variable: y                AIC:              318.9038  \n",
      "Date:               2020-11-23 19:51 BIC:              356.6901  \n",
      "No. Observations:   492              Log-Likelihood:   -150.45   \n",
      "Df Model:           8                LL-Null:          -195.80   \n",
      "Df Residuals:       483              LLR p-value:      3.3608e-16\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     8.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "       Coef.     Std.Err.       z       P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1    -0.0645      0.1583    -0.4075    0.6837    -0.3748     0.2458\n",
      "x2     0.1800      0.1643     1.0957    0.2732    -0.1420     0.5020\n",
      "x3    -0.5571      0.1949    -2.8583    0.0043    -0.9391    -0.1751\n",
      "x4    -0.1794      0.2299    -0.7804    0.4352    -0.6300     0.2712\n",
      "x5    -1.4845      0.2320    -6.3980    0.0000    -1.9393    -1.0298\n",
      "x6     7.4373      0.6490    11.4592    0.0000     6.1652     8.7094\n",
      "x7     1.4003      0.3780     3.7047    0.0002     0.6595     2.1411\n",
      "x8    -0.1487      0.1712    -0.8684    0.3852    -0.4842     0.1869\n",
      "x9     0.0821      0.1854     0.4431    0.6577    -0.2812     0.4455\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Строим базовую модель и анализируем  полученный отчет. Можно сделать вывод, что значимых перменных три но при этом будем использовать найлучшие перменные, это х4 (ALT) и х5 (AST). Будем использовать их для построения наших классификаторов.\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остлавляем только значимые переменные.\n",
    "X_train = X_train[:,[4,5]]\n",
    "X_test = X_test[:,[4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель логистической регрессии.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959349593495935"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Делаем прогноз на тестовой выборке. Уровень качества модели превышает 95%, это значит что  95% объектов распознано верно.\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0]\n",
      " [  5  10]]\n"
     ]
    }
   ],
   "source": [
    "# Строим таблицу сопряженности. Можно сделать вывод, что 5 положительных случая ложно определены как отрицательные. \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Строим область значений. В этом случае отделение линейно. Зелёные точки - больные люди, красные точки - здоровые. Люди с повышенным значением AST более склонны к болезни. \n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, lr.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем необходимые пакеты Keras.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим нейронную сеть прямой передачи сигнала. На входном слое 8 нейрона. relu - функция  позволит учесть наличие линейнносоти в исходных данных. На втором слое выбирем 1 нейрон используя сигмоидальную функцию. \n",
    "cnn = Sequential()\n",
    "cnn.add(Dense(units = 8,  activation = 'relu', input_dim = 2))\n",
    "cnn.add(Dense(units = 1,  activation = 'sigmoid'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7398\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.8496\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8679\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8679\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8720\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8780\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8780\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8780\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8760\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.8760\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2395 - accuracy: 0.8760\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.8760\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.8740\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.8740\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.8740\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.8760\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.8862\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.8963\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9126\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9350\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9390\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9411\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9390\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9390\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9472\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9472\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9451\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9451\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.9451\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9472\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9451\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9451\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9451\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9411\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9431\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9451\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9431\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9451\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9451\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9451\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9431\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9431\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9431\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.9472: 0s - loss: 0.1530 - accuracy: \n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9472\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9492\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9492\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9492\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9492\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9492\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9492\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9512\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9512\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9512\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9512\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9512\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9533\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9533\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9533\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9533\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9533\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9533\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9533\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9533\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9533\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9573\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9533\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9553\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9573\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9553\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9573\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9573\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9553\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9573\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9593\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9573: 0s - loss: 0.1149 - accuracy: 0.\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9593\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9593: 0s - loss: 0.0625 - accuracy: 0.\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9573\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9614\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9614\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9614\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9614\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9614\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9614\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9614\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9614\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9614\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9614\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9614\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9614\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9614\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9614\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9614\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9614\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9614\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9614\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9614\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247e786e880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем нейронную сеть в течении 100 эпох.\n",
    "cnn.fit(X_train, y_train, epochs = 100, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим прогноз на тестовой выборке.\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0]\n",
      " [  3  12]]\n"
     ]
    }
   ],
   "source": [
    "# Строим таблицу сопряженности. Исходя из этого  3 положительных случая ложно определены как отрицательные.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Строим область значений. Они отделяются  не линейно. Однако после усложения модели после увеличения входных нейронов с 2 до 8, качество модели улучшилось. \n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, cnn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('NN (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводы. Исходя из анализа можно сделать вывод, что исходная логистическая модель обладает повышенным качеством и определяет 95% объектов верно. Еще я бы отметил, что позитивные и негативные значения отделяются линейно. Эту линейность мы используем для построения нейронной сети. При использовании стандартных параметров мы получаем качество модели худше, но при этом сохраняется линейность отделения позитивных от негативных. Для улучшения качества модели было принято решение увеличить количество нейронов на первом слое с 2 до 8, что позволило немного улучшить качество модели в целом, однако разделение положительных от отрицательных более не линейно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
